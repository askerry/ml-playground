{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Very Deep Convolutional Networks for Large-Scale Image Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by Simonyan and Zisserman, 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is a straight-forward supervised object recognition task. Given pixel (RGB) image representations, we want to generate labels categorizing the object in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, in the CIFAR-10 challenge, we want to classify 32x32 pixel images into the following 10 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cifar-10 image examples](img/cifar-10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper uses the [ImageNet (ILSVRC) dataset](http://www.image-net.org/challenges/LSVRC) but given the size of that dataset, we implement the same architecture on some smaller image recognition datasets: CIFAR-10 and CIFAR-100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. CIFAR-100 is just like the CIFAR-10, except it has 100 classes containing 600 images each. There are 50000 training images and 10000 test images. State of the art performance is [~96.5% on CIFAR-10](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130) and [~75.7% on CIFAR-100](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d313030)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper implements a fairly standard deep convolutional network architecture. The defining characteristics are the small receptive field sizes (convolutional filters are 3x3) and the stacking of multiple convolutional layers between each pooling step. We implement the best performing (and deepest) neural architecture from the paper: configuration E.\n",
    "\n",
    "![VGG architecture configurations](img/vgg-arch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This architecture was one of the top-performing models submitted to ImageNet (ILSVRC) in 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
